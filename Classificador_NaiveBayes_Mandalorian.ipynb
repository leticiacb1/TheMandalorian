{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Let√≠cia Co√™lho Barbosa\n",
    "\n",
    "Nome: Matheus Silva Melo de Oliveira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextualiza√ß√£o\n",
    "\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas Utilizadas\n",
    "\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install emoji\n",
    "#!pip install pysinonimos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import re \n",
    "import emoji\n",
    "import pysinonimos.sinonimos as sn\n",
    "\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ouvir',\n",
       " 'comparecer',\n",
       " 'observar',\n",
       " 'presenciar',\n",
       " 'testemunhar',\n",
       " 'ver',\n",
       " 'acompanhar',\n",
       " 'assessorar',\n",
       " 'atender',\n",
       " 'auxiliar',\n",
       " 'colaborar',\n",
       " 'cooperar',\n",
       " 'acudir',\n",
       " 'ajudar',\n",
       " 'amparar',\n",
       " 'confortar',\n",
       " 'olhar',\n",
       " 'socorrer',\n",
       " 'caber',\n",
       " 'pertencer',\n",
       " 'competir',\n",
       " 'partejar',\n",
       " 'morar',\n",
       " 'habitar',\n",
       " 'residir',\n",
       " 'conservar-se',\n",
       " 'estar',\n",
       " 'ficar',\n",
       " 'manter-se',\n",
       " 'perdurar',\n",
       " 'permanecer']"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn.Search('assistir').synonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicio_r (palavra):\n",
    "    \n",
    "    nova=sn.Search(palavra).synonyms()   #Buscando sin√¥nimos\n",
    "    P_nova=0\n",
    "    \n",
    "    if nova != 404:\n",
    "        \n",
    "        for i in range(len(nova)):\n",
    "        \n",
    "            if (i != len(nova)-1):\n",
    "                if (nova[i] in palavras_r) and (nova[i] not in lista_r):\n",
    "                    P_nova=rel_relevantes[nova[i]]\n",
    "                    return P_nova\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            else:\n",
    "                return 1\n",
    "    else:\n",
    "        return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicio_i (palavra):\n",
    "    \n",
    "    nova=sn.Search(palavra).synonyms()   #Buscando sin√¥nimos\n",
    "    P_nova=0\n",
    "    \n",
    "    if nova != 404:\n",
    "    \n",
    "        for i in range(len(nova)):\n",
    "            \n",
    "            if (i != len(nova)-1):\n",
    "            \n",
    "                if (nova[i] in palavras_r) and (nova[i] not in lista_i):\n",
    "                    P_nova=rel_relevantes[nova[i]]\n",
    "                    return P_nova\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            else:\n",
    "                return 1\n",
    "    else:\n",
    "        return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste=rel_irrelevantes.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1353"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n= [x for x in palavras_i if x not in teste]\n",
    "len(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3961"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(palavras_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#palavras_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entender\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0010584250635055038"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicio_r('ouvir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['presen√ßa', 'ida', 'apari√ß√£o', 'comparecimento', 'aparecimento', 'surgimento', 'vinda', 'apar√™ncia', 'figura', 'fisionomia', 'imagem', 'porte', 'aspecto', 'configura√ß√£o', 'conforma√ß√£o', 'feitio', 'forma', 'formato', 'talhe', 'comunica√ß√£o', 'adu√ß√£o', 'alega√ß√£o', 'declara√ß√£o', 'exposi√ß√£o', 'manifesta√ß√£o', 'relato', 'difus√£o', 'divulga√ß√£o', 'propaganda', 'veicula√ß√£o', 'abona√ß√£o', 'indica√ß√£o', 'proposi√ß√£o', 'proposta', 'recomenda√ß√£o', 'sugest√£o', 'atua√ß√£o', 'demonstra√ß√£o', 'espet√°culo', 'exibi√ß√£o', 'fun√ß√£o', 'mostra', 'produ√ß√£o', 'sess√£o', 'show', 'ante√¢mbulo', 'introdu√ß√£o', 'pre√¢mbulo', 'pref√°cio', 'pr√≥logo', 'prolus√£o']\n",
      "['gloss√°rio', 'l√©xico', 'vocabul√°rio', 'l√©xicon', 'pai dos burros', 'tesouro', 'tira-d√∫vidas', 'tira-teimas', 'culto', 'douto', 'erudito', 'ilustrado', 'instru√≠do', 'letrado', 'sabedor', 's√°bio']\n"
     ]
    }
   ],
   "source": [
    "for i in ['apresenta√ß√£o','dicion√°rio']:\n",
    "    \n",
    "    apresentacao = sn.Search(i)\n",
    "    sinonimos_de_apresentacao = apresentacao.synonyms()\n",
    "    print(sinonimos_de_apresentacao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmando diret√≥rio de trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\Leticia\\Documents\\INSPER\\2_Semestre\\C_Dados\\Projeto 1\\TheMandalorian\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Banco de Dados\n",
    "\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'mandalorian.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>executivo da disney defendeu demiss√£o de gina ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@daredvevil nao seriooo melhor dia üò≠ volta the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>preciso terminar mandalorian logo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toda vez que eu vejo o baby yoda usando a for√ß...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jon fraveau eu te amo obrigado por fazer the m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevancia\n",
       "0  executivo da disney defendeu demiss√£o de gina ...           0\n",
       "1  @daredvevil nao seriooo melhor dia üò≠ volta the...           1\n",
       "2                  preciso terminar mandalorian logo           1\n",
       "3  toda vez que eu vejo o baby yoda usando a for√ß...           0\n",
       "4  jon fraveau eu te amo obrigado por fazer the m...           1"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the mandalorian √© uma s√©rie com dinheiro e tec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agora comecei mandalorian confiando novamente ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@fepazo1 @gabriel_ns1999 @joelmsimmons @jurand...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu assisti 3 minutos de mandalorian e emocionei</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @anakinwar: j√° ta                          ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevancia\n",
       "0  the mandalorian √© uma s√©rie com dinheiro e tec...           1\n",
       "1  agora comecei mandalorian confiando novamente ...           1\n",
       "2  @fepazo1 @gabriel_ns1999 @joelmsimmons @jurand...           1\n",
       "3    eu assisti 3 minutos de mandalorian e emocionei           1\n",
       "4  rt @anakinwar: j√° ta                          ...           0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador autom√°tico de sentimento\n",
    "\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Definindo Fun√ß√µes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando os tweets retirando pontos desnecessarios\n",
    "def limpeza(tweet):\n",
    "    punctuation = '[!-.:?;\\n|]'                # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern,'', tweet)\n",
    "    return text_subbed\n",
    "\n",
    "#Limpando os tweets retirando emojis\n",
    "def retira_emoji(content: str):\n",
    "        modified = re.sub(emoji.get_emoji_regexp(), r\"\", content)\n",
    "        modified = re.sub(':[^>]+:', '', modified)\n",
    "        modified = re.sub('<[^>]+>', '', modified)\n",
    "        return modified.strip() \n",
    "    \n",
    "# Transformando tweets em lower case:\n",
    "def lower(tweet):\n",
    "    return tweet.lower()\n",
    "\n",
    "\n",
    "# Concatenando tweets palavras+emojis limpos:\n",
    "def concatenar(tweet):\n",
    "    \n",
    "    emojis=re.findall(emoji.get_emoji_regexp(),tweet)                   #Tornando os emojis em strings descritivas\n",
    "    \n",
    "    for i,emoji1 in enumerate(emojis):                              #Alguns emojis n√£o possuem transcri√ß√£o para portugu√™s\n",
    "            if emoji1 in UNICODE_EMOJI['pt']:\n",
    "                emojis[i]=UNICODE_EMOJI['pt'][emoji1].replace(':',',')\n",
    "            else:\n",
    "                emojis[i]=UNICODE_EMOJI['en'][emoji1].replace(':',',')\n",
    "\n",
    "                \n",
    "    g=retira_emoji(tweet)\n",
    "    g=lower(g)\n",
    "    g=g.split()\n",
    "    \n",
    "    for i,word in enumerate(g):\n",
    "        \n",
    "        if 'rt' in word or 'https' in word or '@' in word:\n",
    "            g[i]=g[i].replace(word,'null')\n",
    "        \n",
    "    g=[x for x in g if x!='null']\n",
    "    frase_separada=','.join(g)\n",
    "    emoji_transcrito=','.join(emojis)\n",
    "    return frase_separada+','+emoji_transcrito\n",
    "\n",
    "def frases_to_words (Serie_frases):\n",
    "    \n",
    "    texto=''\n",
    "    \n",
    "    for palavra in Serie_frases:\n",
    "        texto+=str(palavra)                        #Criando uma string gigante com todas as palavras das frases\n",
    "    \n",
    "    lista_palavras=texto.split(',')                #Criando lista das palavras contidas na vari√°vel texto\n",
    "    \n",
    "    return pd.Series(lista_palavras)               #Retornando uma s√©rie de palavras contida nas frases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando palavras em vari√°veis categ√≥ricas:\n",
    "\n",
    "train['Treinamento'] = train['Treinamento'].astype('category')\n",
    "test['Teste'] = test['Teste'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando fun√ß√µes de limpeza:\n",
    "\n",
    "train['Clean']=train['Treinamento'].apply(limpeza)\n",
    "train['Clean']=train['Clean'].apply(concatenar)\n",
    "\n",
    "test['Clean']=test['Teste'].apply(limpeza)\n",
    "test['Clean']=test['Clean'].apply(concatenar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando dados de treino por relev√¢ncia:\n",
    "\n",
    "train_relevantes=train[train['Relevancia']==1]\n",
    "train_irrelevantes=train[train['Relevancia']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.Treinamento[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.Clean[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_irrelevantes['Clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Serie de palavras relevantes e irrelevantes no conjunto treino:\n",
    "\n",
    "palavras_r= frases_to_words(train_relevantes['Clean'])\n",
    "palavras_i= frases_to_words(train_irrelevantes['Clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 nao\n",
       "1                             seriooo\n",
       "2                              melhor\n",
       "3                                 dia\n",
       "4                               volta\n",
       "                    ...              \n",
       "4719                              the\n",
       "4720                      mandalorian\n",
       "4721                                 \n",
       "4722    m√£os_juntas_pele_morena_clara\n",
       "4723                                 \n",
       "Length: 4724, dtype: object"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conferindo resultado:\n",
    "\n",
    "palavras_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando texto com palavras relevantes:\n",
    "\n",
    "texto_r=''\n",
    "\n",
    "for palavra in train_relevantes['Clean']:\n",
    "    texto_r+=str(palavra)\n",
    "#print(texto_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando texto com palavras irrelevantes:\n",
    "texto_i=''\n",
    "\n",
    "for palavra in train_irrelevantes['Clean']:\n",
    "    texto_i+=str(palavra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tranformando cada texto em uma S√©rie de palavras:\n",
    "#palavras_r=pd.Series(texto_r.split(','))\n",
    "#palavras_i=pd.Series(texto_i.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#palavras_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#palavras_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequ√™ncia Relativa das palavras relevantes:\n",
    "#rel_relevantes=palavras_r.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rel_relevantes.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_r=['mandalorian','de','the','√©','que','a','e','o','eu','da','mas','com']\n",
    "#lista_r\n",
    "\n",
    "#for i in lista_r:\n",
    "    #print(rel_relevantes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequ√™ncia Relativa das palavras irrelevantes:\n",
    "#rel_irrelevantes=palavras_i.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rel_irrelevantes.head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_i=['mandalorian','de','the','e','o','a','que','do','√©','eu','da','em','no','um','pra','n√£o','com']\n",
    "\n",
    "#for i in lista_i:\n",
    "    #print(rel_irrelevantes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequ√™ncia relativa das palavras:\n",
    "\n",
    "rel_relevantes=palavras_r.value_counts(normalize=True)\n",
    "rel_irrelevantes=palavras_i.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mandalorian    0.057155\n",
       "               0.041702\n",
       "de             0.040644\n",
       "the            0.031753\n",
       "√©              0.020322\n",
       "dtype: float64"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conferindo resultado:\n",
    "    \n",
    "rel_relevantes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           executivo\n",
       "1                                  da\n",
       "2                              disney\n",
       "3                            defendeu\n",
       "4                            demiss√£o\n",
       "                    ...              \n",
       "8680                              the\n",
       "8681                      mandalorian\n",
       "8682                                 \n",
       "8683    m√£os_juntas_pele_morena_clara\n",
       "8684                                 \n",
       "Length: 8685, dtype: object"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#S√©rie representante do conjunto universo de todas as palavras:\n",
    "\n",
    "palavras_i=palavras_i.tolist()\n",
    "palavras_r=palavras_r.tolist()\n",
    "#total=palavras_i+palavras_r\n",
    "total=pd.Series(palavras_i+palavras_r)             \n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequ√™ncia das palvras no total:\n",
    "\n",
    "rel_total=total.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mandalorian    0.053771\n",
       "de             0.039263\n",
       "               0.029131\n",
       "the            0.028094\n",
       "o              0.021762\n",
       "                 ...   \n",
       "cabelinho      0.000115\n",
       "acha           0.000115\n",
       "desenvolveu    0.000115\n",
       "rola           0.000115\n",
       "chega          0.000115\n",
       "Length: 2162, dtype: float64"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conferindo resultado\n",
    "\n",
    "rel_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando as Probabilidades "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P_{relevante}= \\frac{Palavras_{relevantes}}{Total_{palavras}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P_{irrelevante}= \\frac{Palavras_{irrelevantes}}{Total_{palavras}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onde, sabemos que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P_{relevante}+ P_{irrelevante}=1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilidade tweet ser relevante ou irrelevante:\n",
    "\n",
    "P_r=len(palavras_r)/len(total)\n",
    "P_i=len(palavras_i)/len(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_r=['mandalorian','de','the','√©','que','a','e','o','eu','da','mas','com']\n",
    "lista_i=['mandalorian','de',' ','the','e','o','a','que','do','√©','eu','da','em','no','um','pra','com'] #'n√£o',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingenuidade do classificador Navie Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(R|tweet)= \\frac{P(tweet \\cap R)}{P(tweet)} $$\n",
    "$$ P(tweet|R)= \\frac{P(tweet \\cap R)}{P(R)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(tweet \\cap R) = P(R|tweet) P(tweet) $$\n",
    "$$ P(tweet \\cap R) = P(tweet|R) P(R) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sendo a Probabiliadde de Navie Bayes:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(R|tweet)= \\frac{P(tweet|R) P(R)}{P(tweet)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A probabilidade $P(tweet|R)$, pode ser calculada considerando a independ√™ncia entre as palavras, ou seja, a probabilidade de certa palavra aparecer n√£o interfere na probabilidade de outras:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(tweet|R) = P(palavra1|R)P(palavra2|R)...P(palavraN|R)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos portayndo como porbabilidade de um tweet ser relevante:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(R|tweet) = \\frac{P(palavra1|R)P(palavra2|R)...P(palavraN|R) P(R)}{P(tweet)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogamento, para $P(I|tweet)$, teriamos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(I|tweet)=\\frac{P(palavra1|I)P(palavra2|I)...P(palavraN|I) P(I)}{P(tweet)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, a fun√ß√£o Navie Bayes classificaria como relevante caso:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(R|tweet)>P(I|tweet)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_tweet_r (tweet):\n",
    "    \n",
    "    c=1\n",
    "    \n",
    "    for palavra in tweet.split(','):\n",
    "        if(palavra in palavras_r) and (palavra not in lista_r) :\n",
    "            \n",
    "            c*=rel_relevantes[palavra]\n",
    "        elif palavra in rel_total:\n",
    "            c*=rel_total[palavra]\n",
    "            #c*=dicio_r(palavra)\n",
    "        else:\n",
    "            continue\n",
    "           \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_tweet_i (tweet):\n",
    "    \n",
    "    c=1\n",
    "    \n",
    "    for palavra in tweet.split(','):\n",
    "        if(palavra in palavras_i) and (palavra not in lista_i):\n",
    "            c*=rel_irrelevantes[palavra]\n",
    "        \n",
    "        elif palavra in rel_total: \n",
    "            c*=rel_total[palavra]\n",
    "            #c*=dicio_i(palavra)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#P_tweet_r('dps,de,insistirem,mt,estou,come√ßando,mandalorian,espero,q,realmente,seja,o,caso,de,salva√ß√£o,do,star,wars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P_tweet_i('dps,de,insistirem,mt,estou,come√ßando,mandalorian,espero,q,realmente,seja,o,caso,de,salva√ß√£o,do,star,wars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando Nossa fu√ß√£o Naive_Bayes:\n",
    "\n",
    "def Naive_Bayes (tweet):\n",
    "    if(P_tweet_r(tweet)*P_r > P_tweet_i(tweet)*P_i):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.661988627906574e-51"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " P_tweet_r('dps,de,insistirem,mt,estou,come√ßando,mandalorian,espero,q,realmente,seja,o,caso,de,salva√ß√£o,do,star,wars,alegria,Michel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Michel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.554710958099774e-54"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_tweet_i('dps,de,insistirem,mt,estou,come√ßando,mandalorian,espero,q,realmente,seja,o,caso,de,salva√ß√£o,do,star,wars,alegria, Michel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando uma nova coluna para armazenar resultado da nossa fun√ß√£o Navie_Bayes\n",
    "\n",
    "train['Classificador']=train.Clean.apply(Naive_Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>executivo da disney defendeu demiss√£o de gina ...</td>\n",
       "      <td>0</td>\n",
       "      <td>executivo,da,disney,defendeu,demiss√£o,de,gina,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@daredvevil nao seriooo melhor dia üò≠ volta the...</td>\n",
       "      <td>1</td>\n",
       "      <td>nao,seriooo,melhor,dia,volta,the,mandalorian,p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>preciso terminar mandalorian logo</td>\n",
       "      <td>1</td>\n",
       "      <td>preciso,terminar,mandalorian,logo,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toda vez que eu vejo o baby yoda usando a for√ß...</td>\n",
       "      <td>0</td>\n",
       "      <td>toda,vez,que,eu,vejo,o,baby,yoda,usando,a,for√ß...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jon fraveau eu te amo obrigado por fazer the m...</td>\n",
       "      <td>1</td>\n",
       "      <td>jon,fraveau,eu,te,amo,obrigado,por,fazer,the,m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>√∫ltimo ep de mandalorian, n√£o estou preparada</td>\n",
       "      <td>1</td>\n",
       "      <td>√∫ltimo,ep,de,mandalorian,n√£o,estou,preparada,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>minha prioridade agora √© terminar the mandalorian</td>\n",
       "      <td>1</td>\n",
       "      <td>minha,prioridade,agora,√©,terminar,the,mandalor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>agora vou come√ßar a ver the mandalorian üôèüèº</td>\n",
       "      <td>1</td>\n",
       "      <td>agora,vou,come√ßar,a,ver,the,mandalorian,,m√£os_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>@jurandirfilho tem nem compara√ß√£o n√© man, mand...</td>\n",
       "      <td>0</td>\n",
       "      <td>tem,nem,compara√ß√£o,n√©,man,mandalorian,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>mandalorian por favor retire seu capacete, que...</td>\n",
       "      <td>0</td>\n",
       "      <td>mandalorian,por,favor,retire,seu,capacete,quer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Relevancia  \\\n",
       "0    executivo da disney defendeu demiss√£o de gina ...           0   \n",
       "1    @daredvevil nao seriooo melhor dia üò≠ volta the...           1   \n",
       "2                    preciso terminar mandalorian logo           1   \n",
       "3    toda vez que eu vejo o baby yoda usando a for√ß...           0   \n",
       "4    jon fraveau eu te amo obrigado por fazer the m...           1   \n",
       "..                                                 ...         ...   \n",
       "495      √∫ltimo ep de mandalorian, n√£o estou preparada           1   \n",
       "496  minha prioridade agora √© terminar the mandalorian           1   \n",
       "497         agora vou come√ßar a ver the mandalorian üôèüèº           1   \n",
       "498  @jurandirfilho tem nem compara√ß√£o n√© man, mand...           0   \n",
       "499  mandalorian por favor retire seu capacete, que...           0   \n",
       "\n",
       "                                                 Clean  Classificador  \n",
       "0    executivo,da,disney,defendeu,demiss√£o,de,gina,...              0  \n",
       "1    nao,seriooo,melhor,dia,volta,the,mandalorian,p...              1  \n",
       "2                   preciso,terminar,mandalorian,logo,              1  \n",
       "3    toda,vez,que,eu,vejo,o,baby,yoda,usando,a,for√ß...              0  \n",
       "4    jon,fraveau,eu,te,amo,obrigado,por,fazer,the,m...              1  \n",
       "..                                                 ...            ...  \n",
       "495      √∫ltimo,ep,de,mandalorian,n√£o,estou,preparada,              1  \n",
       "496  minha,prioridade,agora,√©,terminar,the,mandalor...              1  \n",
       "497  agora,vou,come√ßar,a,ver,the,mandalorian,,m√£os_...              1  \n",
       "498             tem,nem,compara√ß√£o,n√©,man,mandalorian,              0  \n",
       "499  mandalorian,por,favor,retire,seu,capacete,quer...              0  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.924"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Porgentagem de acerto no conjunto de Treino:\n",
    "\n",
    "x=train.loc[(train['Classificador']==1)&(train['Relevancia']==1),:].shape[0]\n",
    "y=train.loc[(train['Classificador']==0)&(train['Relevancia']==0),:].shape[0]\n",
    "(x+y)/train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Classificador']=test.Clean.apply(Naive_Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=test.loc[(test['Classificador']==1)&(test['Relevancia']==1),:].shape[0]\n",
    "y=test.loc[(test['Classificador']==0)&(test['Relevancia']==0),:].shape[0]\n",
    "(x+y)/test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificador</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.391111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.048889</td>\n",
       "      <td>0.404444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificador         0         1\n",
       "Relevancia                       \n",
       "0              0.155556  0.391111\n",
       "1              0.048889  0.404444"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fp=test.loc[(test['Classificador']==0)&(test['Relevancia']==1),:].shape[0]\n",
    "# tp=test.loc[(test['Classificador']==1)&(test['Relevancia']==1),:].shape[0]\n",
    "# fn=test.loc[(test['Classificador']==1)&(test['Relevancia']==0),:].shape[0]\n",
    "# tn=test.loc[(test['Classificador']==0)&(test['Relevancia']==0),:].shape[0]\n",
    "\n",
    "# test['Classificador']=\n",
    "pd.crosstab(test.Relevancia,test.Classificador,normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
