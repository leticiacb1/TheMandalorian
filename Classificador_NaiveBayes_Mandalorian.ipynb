{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Let√≠cia Co√™lho Barbosa\n",
    "\n",
    "Nome: Matheus Silva Melo de Oliveira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\mathe_vz6v46f\\OneDrive\\Documentos\\Arquivos INSPER 2¬∞ SEMESTRE\\C-Dados\\TheMandalorian\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'mandalorian.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>executivo da disney defendeu demiss√£o de gina ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@daredvevil nao seriooo melhor dia üò≠ volta the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>preciso terminar mandalorian logo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toda vez que eu vejo o baby yoda usando a for√ß...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jon fraveau eu te amo obrigado por fazer the m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevancia\n",
       "0  executivo da disney defendeu demiss√£o de gina ...           0\n",
       "1  @daredvevil nao seriooo melhor dia üò≠ volta the...           1\n",
       "2                  preciso terminar mandalorian logo           1\n",
       "3  toda vez que eu vejo o baby yoda usando a for√ß...           0\n",
       "4  jon fraveau eu te amo obrigado por fazer the m...           1"
      ]
     },
     "execution_count": 984,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the mandalorian √© uma s√©rie com dinheiro e tec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agora comecei mandalorian confiando novamente ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@fepazo1 @gabriel_ns1999 @joelmsimmons @jurand...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu assisti 3 minutos de mandalorian e emocionei</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @anakinwar: j√° ta                          ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevancia\n",
       "0  the mandalorian √© uma s√©rie com dinheiro e tec...           1\n",
       "1  agora comecei mandalorian confiando novamente ...           1\n",
       "2  @fepazo1 @gabriel_ns1999 @joelmsimmons @jurand...           1\n",
       "3    eu assisti 3 minutos de mandalorian e emocionei           1\n",
       "4  rt @anakinwar: j√° ta                          ...           0"
      ]
     },
     "execution_count": 985,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "ESCREVA AQUI..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import emoji\n",
    "from emoji import UNICODE_EMOJI\n",
    "\n",
    "train['Treinamento'] = train['Treinamento'].astype('category')\n",
    "test['Teste'] = test['Teste'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando os tweets retirando pontos desnecessarios\n",
    "def limpeza(tweet):\n",
    "    punctuation = '[!-.:?;\\n|]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern,'', tweet)\n",
    "    return text_subbed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retira_emoji(content: str):\n",
    "        modified = re.sub(emoji.get_emoji_regexp(), r\"\", content)\n",
    "        modified = re.sub(':[^>]+:', '', modified)\n",
    "        modified = re.sub('<[^>]+>', '', modified)\n",
    "        return modified.strip() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(tweet):\n",
    "    return tweet.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando limpeza necess√°ria, e quebrando em listas\n",
    "def concatenar(tweet):\n",
    "    \n",
    "    #Tornando os emojis em strings descritivas\n",
    "    emojis=re.findall(emoji.get_emoji_regexp(),tweet)\n",
    "    #Algus emojis n√£o possuem transcri√ß√£o para portugu√™s\n",
    "    for i,emoji1 in enumerate(emojis):\n",
    "            if emoji1 in UNICODE_EMOJI['pt']:\n",
    "                emojis[i]=UNICODE_EMOJI['pt'][emoji1].replace(':',',')\n",
    "            else:\n",
    "                emojis[i]=UNICODE_EMOJI['en'][emoji1].replace(':',',')\n",
    "\n",
    "                \n",
    "    g=retira_emoji(tweet)\n",
    "    g=lower(g)\n",
    "    g=g.split()\n",
    "    \n",
    "    for i,word in enumerate(g):\n",
    "        \n",
    "        if 'rt' in word or 'https' in word or '@' in word:\n",
    "            g[i]=g[i].replace(word,'null')\n",
    "        \n",
    "    g=[x for x in g if x!='null']\n",
    "    k=','.join(g)\n",
    "    m=','.join(emojis)\n",
    "    return k+','+m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Clean']=train['Treinamento'].apply(limpeza)\n",
    "train['Clean']=train['Clean'].apply(concatenar)\n",
    "\n",
    "test['Clean']=test['Teste'].apply(limpeza)\n",
    "test['Clean']=test['Clean'].apply(concatenar)\n",
    "\n",
    "train_relevantes=train[train['Relevancia']==1]\n",
    "train_irrelevantes=train[train['Relevancia']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'obrigada aos envolvidos por mandalorian, √© simplesmente a melhor coisa que eu ja assisti na minha vida. meu lado f√£ de star wars esta em √™xtase nesse exato momento'"
      ]
     },
     "execution_count": 993,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Treinamento[23]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mandalorian,pobre,n√£o,tem,dinheiro,para,o,peitoral,,rosto_deprimido,'"
      ]
     },
     "execution_count": 994,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Clean[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando texto com palavras relevantes:\n",
    "\n",
    "texto_r=''\n",
    "\n",
    "for palavra in train_relevantes['Clean']:\n",
    "    texto_r+=str(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando texto com palavras irrelevantes:\n",
    "texto_i=''\n",
    "\n",
    "for palavra in train_irrelevantes['Clean']:\n",
    "    texto_i+=str(palavra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 nao\n",
       "1                             seriooo\n",
       "2                              melhor\n",
       "3                                 dia\n",
       "4                               volta\n",
       "                    ...              \n",
       "4719                              the\n",
       "4720                      mandalorian\n",
       "4721                                 \n",
       "4722    m√£os_juntas_pele_morena_clara\n",
       "4723                                 \n",
       "Length: 4724, dtype: object"
      ]
     },
     "execution_count": 997,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tranformando cada texto em uma S√©rie de palavras:\n",
    "palavras_r=pd.Series(texto_r.split(','))\n",
    "palavras_i=pd.Series(texto_i.split(','))\n",
    "palavras_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 nao\n",
       "1                             seriooo\n",
       "2                              melhor\n",
       "3                                 dia\n",
       "4                               volta\n",
       "                    ...              \n",
       "4719                              the\n",
       "4720                      mandalorian\n",
       "4721                                 \n",
       "4722    m√£os_juntas_pele_morena_clara\n",
       "4723                                 \n",
       "Length: 4724, dtype: object"
      ]
     },
     "execution_count": 998,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       executivo\n",
       "1              da\n",
       "2          disney\n",
       "3        defendeu\n",
       "4        demiss√£o\n",
       "          ...    \n",
       "3956          ver\n",
       "3957            o\n",
       "3958        pedro\n",
       "3959       pascal\n",
       "3960             \n",
       "Length: 3961, dtype: object"
      ]
     },
     "execution_count": 999,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequ√™ncia Relativa das palavras relevantes:\n",
    "\n",
    "rel_relevantes=palavras_r.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mandalorian    0.057155\n",
       "               0.041702\n",
       "de             0.040644\n",
       "the            0.031753\n",
       "√©              0.020322\n",
       "a              0.020110\n",
       "que            0.019898\n",
       "o              0.019898\n",
       "e              0.019687\n",
       "eu             0.017570\n",
       "da             0.010584\n",
       "mas            0.008891\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1001,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_relevantes.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0571549534292972\n",
      "0.04064352243861134\n",
      "0.03175275190516511\n",
      "0.02032176121930567\n",
      "0.01989839119390347\n",
      "0.02011007620660457\n",
      "0.01968670618120237\n",
      "0.01989839119390347\n",
      "0.017569856054191365\n",
      "0.010584250635055038\n",
      "0.008890770533446233\n",
      "0.007620660457239628\n"
     ]
    }
   ],
   "source": [
    "lista_r=['mandalorian','de','the','√©','que','a','e','o','eu','da','mas','com']\n",
    "lista_r\n",
    "\n",
    "for i in lista_r:\n",
    "    print(rel_relevantes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequ√™ncia Relativa das palavras irrelevantes:\n",
    "rel_irrelevantes=palavras_i.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mandalorian    0.049735\n",
       "de             0.037617\n",
       "o              0.023984\n",
       "the            0.023731\n",
       "e              0.023479\n",
       "a              0.020197\n",
       "que            0.018177\n",
       "eu             0.015148\n",
       "               0.014138\n",
       "do             0.012876\n",
       "√©              0.011866\n",
       "da             0.010856\n",
       "em             0.010098\n",
       "um             0.009089\n",
       "n√£o            0.009089\n",
       "no             0.009089\n",
       "pra            0.008584\n",
       "com            0.007574\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1004,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_irrelevantes.head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049734915425397624\n",
      "0.037616763443574855\n",
      "0.02373138096440293\n",
      "0.02347891946478162\n",
      "0.023983842464024237\n",
      "0.02019691996970462\n",
      "0.018177227972734158\n",
      "0.012875536480686695\n",
      "0.011865690482201464\n",
      "0.015147689977278465\n",
      "0.010855844483716234\n",
      "0.01009845998485231\n",
      "0.009088613986367079\n",
      "0.009088613986367079\n",
      "0.008583690987124463\n",
      "0.009088613986367079\n",
      "0.007573844988639233\n"
     ]
    }
   ],
   "source": [
    "lista_i=['mandalorian','de','the','e','o','a','que','do','√©','eu','da','em','no','um','pra','n√£o','com']\n",
    "\n",
    "for i in lista_i:\n",
    "    print(rel_irrelevantes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           executivo\n",
       "1                                  da\n",
       "2                              disney\n",
       "3                            defendeu\n",
       "4                            demiss√£o\n",
       "                    ...              \n",
       "8680                              the\n",
       "8681                      mandalorian\n",
       "8682                                 \n",
       "8683    m√£os_juntas_pele_morena_clara\n",
       "8684                                 \n",
       "Length: 8685, dtype: object"
      ]
     },
     "execution_count": 1006,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Serie de todas as palavras:\n",
    "\n",
    "palavras_i=palavras_i.tolist()\n",
    "palavras_r=palavras_r.tolist()\n",
    "\n",
    "total=palavras_i+palavras_r\n",
    "\n",
    "total=pd.Series(total)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequ√™ncia das palvras no total:\n",
    "\n",
    "rel_total=total.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando Probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilidade tweet ser relevante ou irrelevante:\n",
    "\n",
    "P_r=len(palavras_r)/len(total)\n",
    "P_i=len(palavras_i)/len(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_r=['mandalorian','de','the','√©','que','a','e','o','eu','da','mas','com']\n",
    "lista_i=['mandalorian','de',' ','the','e','o','a','que','do','√©','eu','da','em','no','um','pra','n√£o','com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_tweet_r (tweet):\n",
    "    \n",
    "    c=1\n",
    "    \n",
    "    for palavra in tweet.split(','):\n",
    "        if(palavra in palavras_r) and (palavra not in lista_r) :\n",
    "            \n",
    "            c*=rel_relevantes[palavra]\n",
    "        elif palavra in rel_total:\n",
    "             c*=rel_total[palavra]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_tweet_i (tweet):\n",
    "    \n",
    "    c=1\n",
    "    \n",
    "    for palavra in tweet.split(','):\n",
    "        if(palavra in palavras_i) and (palavra not in lista_i):\n",
    "            c*=rel_irrelevantes[palavra]\n",
    "        elif palavra in rel_total:\n",
    "            c*=rel_total[palavra]\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1011617139115327e-47"
      ]
     },
     "execution_count": 1040,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_tweet_r('dps,de,insistirem,mt,estou,come√ßando,mandalorian,espero,q,realmente,seja,o,caso,de,salva√ß√£o,do,star,wars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.751332335548268e-51"
      ]
     },
     "execution_count": 1041,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_tweet_i('dps,de,insistirem,mt,estou,come√ßando,mandalorian,espero,q,realmente,seja,o,caso,de,salva√ß√£o,do,star,wars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes (tweet):\n",
    "    if(P_tweet_r(tweet)*P_r > P_tweet_i(tweet)*P_i):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Classificador']=train.Clean.apply(Naive_Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.924"
      ]
     },
     "execution_count": 1044,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=train.loc[(train['Classificador']==1)&(train['Relevancia']==1),:].shape[0]\n",
    "y=train.loc[(train['Classificador']==0)&(train['Relevancia']==0),:].shape[0]\n",
    "(x+y)/train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the mandalorian √© uma s√©rie com dinheiro e tec...</td>\n",
       "      <td>1</td>\n",
       "      <td>the,mandalorian,√©,uma,s√©rie,com,dinheiro,e,tec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agora comecei mandalorian confiando novamente ...</td>\n",
       "      <td>1</td>\n",
       "      <td>agora,comecei,mandalorian,confiando,novamente,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@fepazo1 @gabriel_ns1999 @joelmsimmons @jurand...</td>\n",
       "      <td>1</td>\n",
       "      <td>the,mandalorian,ousou,ao,trazer,personagens,do...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu assisti 3 minutos de mandalorian e emocionei</td>\n",
       "      <td>1</td>\n",
       "      <td>eu,assisti,3,minutos,de,mandalorian,e,emocionei,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @anakinwar: j√° ta                          ...</td>\n",
       "      <td>0</td>\n",
       "      <td>j√°,ta,mas,m√£echorando,aquele,final,dednv,garot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>t√¥ com saudade de the mandalorian, acho que vo...</td>\n",
       "      <td>1</td>\n",
       "      <td>t√¥,com,saudade,de,the,mandalorian,acho,que,vou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>meu deus pedro pascal √© o mandalorian üò±üò±üò±üò±üò±üò±üò±</td>\n",
       "      <td>1</td>\n",
       "      <td>meu,deus,pedro,pascal,√©,o,mandalorian,,rosto_g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>@39marukin @ghostjacobs tem. assisti l√°.\\nagor...</td>\n",
       "      <td>1</td>\n",
       "      <td>tem,assisti,l√°agora,finalmente,vou,come√ßar,man...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>@ip_mandalorian @tmarretamma ficou parecendo o...</td>\n",
       "      <td>1</td>\n",
       "      <td>ficou,parecendo,o,pequenino,do,filme,,rolando_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>@tebaldopaladino e nem acabamos a maratona de ...</td>\n",
       "      <td>0</td>\n",
       "      <td>e,nem,acabamos,a,maratona,de,star,wars,e,tem,o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Relevancia  \\\n",
       "0    the mandalorian √© uma s√©rie com dinheiro e tec...           1   \n",
       "1    agora comecei mandalorian confiando novamente ...           1   \n",
       "2    @fepazo1 @gabriel_ns1999 @joelmsimmons @jurand...           1   \n",
       "3      eu assisti 3 minutos de mandalorian e emocionei           1   \n",
       "4    rt @anakinwar: j√° ta                          ...           0   \n",
       "..                                                 ...         ...   \n",
       "220  t√¥ com saudade de the mandalorian, acho que vo...           1   \n",
       "221      meu deus pedro pascal √© o mandalorian üò±üò±üò±üò±üò±üò±üò±           1   \n",
       "222  @39marukin @ghostjacobs tem. assisti l√°.\\nagor...           1   \n",
       "223  @ip_mandalorian @tmarretamma ficou parecendo o...           1   \n",
       "224  @tebaldopaladino e nem acabamos a maratona de ...           0   \n",
       "\n",
       "                                                 Clean  Classificador  \n",
       "0    the,mandalorian,√©,uma,s√©rie,com,dinheiro,e,tec...              1  \n",
       "1    agora,comecei,mandalorian,confiando,novamente,...              1  \n",
       "2    the,mandalorian,ousou,ao,trazer,personagens,do...              1  \n",
       "3     eu,assisti,3,minutos,de,mandalorian,e,emocionei,              1  \n",
       "4    j√°,ta,mas,m√£echorando,aquele,final,dednv,garot...              1  \n",
       "..                                                 ...            ...  \n",
       "220  t√¥,com,saudade,de,the,mandalorian,acho,que,vou...              1  \n",
       "221  meu,deus,pedro,pascal,√©,o,mandalorian,,rosto_g...              1  \n",
       "222  tem,assisti,l√°agora,finalmente,vou,come√ßar,man...              1  \n",
       "223  ficou,parecendo,o,pequenino,do,filme,,rolando_...              1  \n",
       "224  e,nem,acabamos,a,maratona,de,star,wars,e,tem,o...              1  \n",
       "\n",
       "[225 rows x 4 columns]"
      ]
     },
     "execution_count": 1050,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Classificador']=test.Clean.apply(Naive_Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 1047,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=test.loc[(test['Classificador']==1)&(test['Relevancia']==1),:].shape[0]\n",
    "y=test.loc[(test['Classificador']==0)&(test['Relevancia']==0),:].shape[0]\n",
    "(x+y)/test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificador</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.391111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.048889</td>\n",
       "      <td>0.404444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificador         0         1\n",
       "Relevancia                       \n",
       "0              0.155556  0.391111\n",
       "1              0.048889  0.404444"
      ]
     },
     "execution_count": 1052,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fp=test.loc[(test['Classificador']==0)&(test['Relevancia']==1),:].shape[0]\n",
    "# tp=test.loc[(test['Classificador']==1)&(test['Relevancia']==1),:].shape[0]\n",
    "# fn=test.loc[(test['Classificador']==1)&(test['Relevancia']==0),:].shape[0]\n",
    "# tn=test.loc[(test['Classificador']==0)&(test['Relevancia']==0),:].shape[0]\n",
    "\n",
    "# test['Classificador']=\n",
    "pd.crosstab(test.Relevancia,test.Classificador,normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
