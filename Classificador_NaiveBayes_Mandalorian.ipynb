{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Let√≠cia Co√™lho Barbosa\n",
    "\n",
    "Nome: Matheus Silva Melo de Oliveira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextualiza√ß√£o\n",
    "\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O produto escolhido para a classifica√ß√£o foi a t√£o falada e renomada s√©rie do Universo de Star Wars,<em><b>The Mandalorian</b></em> atualmente vinculado, a Disney e transmitido no servi√ßo de assinatura Disney+.\n",
    "\n",
    "<br>\n",
    "\n",
    "A classifica√ß√£o foi realizada com intuito de analisar caso internautas ou poss√≠veis consumidores da s√©rie comentam sobre esta na rede social Twitter. O crit√©rio utilizado para relev√¢ncia foi caso o usu√°rio fizesse algum coment√°rio que remetia algum la√ßo de intensidade em rela√ß√£o √† s√©rie, positivo ou n√£o, como elogiando algum cap√≠tulo, sentindo saudade da s√©rie ou criticando algum aspecto relevante √† obra. Tweets que falavam apenas de aspectos tangentes √† esse certame, como elogios ou coment√°rios a atores da obra, listagens no qual √† s√©rie se enquadra e vagas men√ß√µes sobre a s√©rie foram consideradas como irrelevantes nessa classifica√ß√£o.\n",
    "\n",
    "<em>Alguns dos principais t√≥picos contidos nos tweets</em>\n",
    "- Elogiando epis√≥dio final da segunda temporada\n",
    "- Elogiando o personagem principal da obra, Mandaloriano ou o personagem em CGI, apeliadado de \"Baby Yoda\"\n",
    "- Elogios √† s√©rie, com adv√©rbios que remetem falta da s√©rie, que est√° em hiato, ou elogios √† hist√≥ria\n",
    "- Coment√°rios alheios a atores e atrizes da obra, como Pedro Pascal\n",
    "- Compara√ß√µes com outras obras, principalmente Wandavision, do mesmo servi√ßo de streaming Disney+\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src=\"mandalorian_assets/mandalorian.gif\" width=500 style=\"float: center; margin: 0px 0px 10px 10px\"></center>\n",
    "<center><b>Cena da s√©rie do Disney+</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas Utilizadas\n",
    "\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1896,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install emoji\n",
    "#!pip install pysinonimos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1897,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas de uso recorrente\n",
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1898,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas com uso mais estrito com foco na classifica√ß√£o\n",
    "import re \n",
    "import emoji\n",
    "import pysinonimos.sinonimos as sn\n",
    "import nltk\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmando diret√≥rio de trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1899,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\mathe_vz6v46f\\OneDrive\\Documentos\\Arquivos INSPER 2¬∞ SEMESTRE\\C-Dados\\TheMandalorian\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Banco de Dados\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1900,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'mandalorian_assets/mandalorian.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1901,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>executivo da disney defendeu demiss√£o de gina ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@daredvevil nao seriooo melhor dia üò≠ volta the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>preciso terminar mandalorian logo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toda vez que eu vejo o baby yoda usando a for√ß...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jon fraveau eu te amo obrigado por fazer the m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevancia\n",
       "0  executivo da disney defendeu demiss√£o de gina ...           0\n",
       "1  @daredvevil nao seriooo melhor dia üò≠ volta the...           1\n",
       "2                  preciso terminar mandalorian logo           1\n",
       "3  toda vez que eu vejo o baby yoda usando a for√ß...           0\n",
       "4  jon fraveau eu te amo obrigado por fazer the m...           1"
      ]
     },
     "execution_count": 1901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1902,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the mandalorian √© uma s√©rie com dinheiro e tec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agora comecei mandalorian confiando novamente ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@fepazo1 @gabriel_ns1999 @joelmsimmons @jurand...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu assisti 3 minutos de mandalorian e emocionei</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @anakinwar: j√° ta                          ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevancia\n",
       "0  the mandalorian √© uma s√©rie com dinheiro e tec...           1\n",
       "1  agora comecei mandalorian confiando novamente ...           1\n",
       "2  @fepazo1 @gabriel_ns1999 @joelmsimmons @jurand...           1\n",
       "3    eu assisti 3 minutos de mandalorian e emocionei           1\n",
       "4  rt @anakinwar: j√° ta                          ...           0"
      ]
     },
     "execution_count": 1902,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste').drop('Relevancia',axis=1)\n",
    "test['Relevancia']=test['New']\n",
    "test=test.drop('New',axis=1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador autom√°tico de sentimento\n",
    "\n",
    "------------------------------------------------------------\n",
    "Iniciando o tratamento e cria√ß√£o do modelo de classifica√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Definindo Fun√ß√µes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1903,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando os tweets retirando pontos desnecessarios\n",
    "def limpeza(tweet):\n",
    "    punctuation = '[@\\-/!.:?;,''\"]'             \n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern,'', tweet)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1904,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando os tweets retirando emojis\n",
    "def retira_emoji(content: str):\n",
    "        modified = re.sub(emoji.get_emoji_regexp(), r\"\", content)\n",
    "        modified = re.sub(':[^>]+:', '', modified)\n",
    "        return modified.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1905,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mathe_vz6v46f\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Armazenando listas com preposi√ß√µes na l√≠ngua portuguesa\n",
    "nltk.download('stopwords')\n",
    "prep = nltk.corpus.stopwords.words('portuguese')\n",
    "prep.append('')\n",
    "\n",
    "# Define fun√ß√£o que aplica remo√ß√£o de preposi√ß√µes\n",
    "def limpa_preposicao(lista):\n",
    "    sem_prep=[]     \n",
    "    for palavra in lista: \n",
    "        if palavra in prep: \n",
    "            continue\n",
    "        else:\n",
    "            sem_prep.append(palavra)\n",
    "            \n",
    "    return sem_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1906,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando tweets em lower case:\n",
    "def lower(tweet):\n",
    "    return tweet.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1907,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retira escritas comuns em tweets, mas irrelevantes para an√°lise de dados\n",
    "def tweet_to_frase(lista):\n",
    "    '''\n",
    "    Aqui desconsideraremos as palavras \"mandalorian\" ou \"the\", visto que essas\n",
    "    pertencem a  basicamente todo tweet analisado, e sua presen√ßa ir√° apenas impactar a base de dados\n",
    "    com maior perncentualidade, no caso a de \"relevantes\".\n",
    "    '''\n",
    "    for i,word in enumerate(lista):\n",
    "        if 'rt' in word or 'https' in word or'the' in word or 'mandalorian' in word:\n",
    "            lista[i]=lista[i].replace(word,'null')\n",
    "    new_list=[x for x in lista if x!='null']\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1908,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tornando os emojis em strings descritivas\n",
    "#Alguns emojis n√£o possuem transcri√ß√£o para portugu√™s\n",
    "def transcreve_emoji(lista):\n",
    "    emojis=re.findall(emoji.get_emoji_regexp(),lista)                  \n",
    "    for i,emoji1 in enumerate(emojis):                              \n",
    "            if emoji1 in UNICODE_EMOJI['pt']:\n",
    "                emojis[i]=UNICODE_EMOJI['pt'][emoji1].replace(':',',')\n",
    "            else:\n",
    "                emojis[i]=UNICODE_EMOJI['en'][emoji1].replace(':',',')\n",
    "    return emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1909,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando lista em string\n",
    "def list_to_string(lista):\n",
    "    return ','.join(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1910,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando string em lista\n",
    "def string_to_list(string):\n",
    "    return string.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1911,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando todas as fun√ß√µes acima no df:\n",
    "def aplica(tweet):\n",
    "    \n",
    "    #captando emojis\n",
    "    emoji_transcrito=list_to_string(transcreve_emoji(tweet))\n",
    "    \n",
    "    #aplicando todas as fun√ß√µes definidas\n",
    "    frase_separada=list_to_string(tweet_to_frase(limpa_preposicao(string_to_list(limpeza(lower(retira_emoji(tweet)))))))\n",
    "    \n",
    "    #retornando uma string limpa e com emojis transcritos\n",
    "    return frase_separada+','+emoji_transcrito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1912,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frases_to_words (Serie_frases):\n",
    "    \n",
    "    texto=''\n",
    "    \n",
    "    for palavra in Serie_frases:\n",
    "        texto+=str(palavra)                        #Criando uma string gigante com todas as palavras das frases\n",
    "    \n",
    "    lista_palavras=texto.split(',')                #Criando lista das palavras contidas na vari√°vel texto\n",
    "    return pd.Series(lista_palavras)               #Retornando uma s√©rie de palavras contida nas frases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1913,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando palavras em vari√°veis categ√≥ricas:\n",
    "train['Treinamento'] = train['Treinamento'].astype('category')\n",
    "test['Teste'] = test['Teste'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1914,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando fun√ß√µes de limpeza e certifica√ß√£o no dataframe de treinamento da base de dados:\n",
    "train['Clean']=train['Treinamento'].apply(aplica)\n",
    "test['Clean']=test['Teste'].apply(aplica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1915,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando dados de treino por relev√¢ncia:\n",
    "train_relevantes=train[train['Relevancia']==1]\n",
    "train_irrelevantes=train[train['Relevancia']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1916,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Serie de palavras relevantes e irrelevantes no conjunto treino:\n",
    "palavras_r= frases_to_words(train_relevantes['Clean'])\n",
    "palavras_i= frases_to_words(train_irrelevantes['Clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1917,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequ√™ncias relativas das palavras:\n",
    "rel_relevantes=palavras_r.value_counts(normalize=True)\n",
    "rel_irrelevantes=palavras_i.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1918,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardando uma lista as palavras pertencentes aos tweets relevantes:\n",
    "list_i=palavras_i.tolist()\n",
    "\n",
    "#Guardando uma lista as palavras pertencentes aos tweets irrelevantes:\n",
    "list_r=palavras_r.tolist()\n",
    "\n",
    "#Guardando em uma lista todas as palavras poss√≠veis na base de dados (SEM REPETI√á√ïES):\n",
    "elementos_nao_repetidos=set(list_i+list_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1919,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S√©rie representante do conjunto universo de todas as palavras:\n",
    "#total=palavras_i+palavras_r\n",
    "total=pd.Series(list_i+list_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1920,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequ√™ncia relativa das palavras no total:\n",
    "rel_total=total.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando as Probabilidades "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P_{relevante}= \\frac{Palavras_{relevantes}}{Total_{palavras}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P_{irrelevante}= \\frac{Palavras_{irrelevantes}}{Total_{palavras}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onde, sabemos que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P_{relevante}+ P_{irrelevante}=1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1921,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilidade tweet ser relevante ou irrelevante:\n",
    "P_r=len(palavras_r)/len(total)\n",
    "P_i=len(palavras_i)/len(total)\n",
    "\n",
    "#Garantindo a verdade acima\n",
    "assert P_r+P_i==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingenuidade do classificador Na√Øve-Bayes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(R|tweet)= \\frac{P(tweet \\cap R)}{P(tweet)} $$\n",
    "$$ P(tweet|R)= \\frac{P(tweet \\cap R)}{P(R)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(tweet \\cap R) = P(R|tweet) P(tweet) $$\n",
    "$$ P(tweet \\cap R) = P(tweet|R) P(R) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sendo a Probabilidade de Na√Øve-Bayes:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(R|tweet)= \\frac{P(tweet|R) P(R)}{P(tweet)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A probabilidade $P(tweet|R)$, pode ser calculada considerando a independ√™ncia entre as palavras, ou seja, a probabilidade de certa palavra aparecer n√£o interfere na probabilidade de outras:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(tweet|R) = P(palavra1|R)P(palavra2|R)...P(palavraN|R)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos portanto como probabilidade de um tweet ser relevante:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(R|tweet) = \\frac{P(palavra1|R)P(palavra2|R)...P(palavraN|R) P(R)}{P(tweet)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogamente, para $P(I|tweet)$, teriamos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(I|tweet)=\\frac{P(palavra1|I)P(palavra2|I)...P(palavraN|I) P(I)}{P(tweet)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso apare√ßa uma palavra estranha ou que n√£o esteja na base de dados, precisamos amplificar nosse leque de equa√ß√µes utilizando um recurso matem√°tico conhecido como <b><em>Suaviza√ß√£o de Laplace</em></b>, que consiste em basicamente \"incluir\" a nova palavra no √¢mbito das probabilidades relativas de uma determinada palavra ser classificada como Relevante ou Irrelevante.\n",
    "\n",
    "Para realizar tal recurso, devemos analisar quantas vezes a palavra analisada aparece no absolutamente na comapra√ß√£o em quest√£o, seja relevante ou irrelavante, somar uma unidade (que evita o <b>0</b>) no numerador, e somar a quantidade de \"poss√≠veis palavras no denominador\", isto √© a quantidade de palavras √∫nicas pertencentes ao dataset de tweets relevantes ou irrelevantes. Matematicamente teremos:\n",
    "\n",
    "$$P(palavra1|R) = \\frac{F_{AR}+1}{P_{R}+P_p}$$\n",
    "\n",
    "$$P(palavra1|I) = \\frac{F_{AI}+1}{P_{I}+P_p}$$\n",
    "\n",
    "Onde: \n",
    "\n",
    "$ F_{AR}$: Frequ√™ncia absoluta de tweets relevantes \n",
    "\n",
    "$ F_{AI}$: Frequ√™ncia absoluta de tweets relevantes\n",
    "    \n",
    "$P_{R}$: Todas as palavras pertencentes aos tweets rotulados como relevantes\n",
    "    \n",
    "$P_{I}$: Todas as palavras pertencentes aos tweets rotulados como irrelevantes\n",
    "\n",
    "$P_p$: Todas as palavras poss√≠veis na base de dados de treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto,feitas modifica√ß√µes, palavra a palavra, a fun√ß√£o Na√Øve-Bayes classificaria como relevante caso:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{P(R|tweet)P(Relevante)}{P(tweet)} > \\frac{P(I|tweet)P(Irrelevante)}{P(tweet)}$$\n",
    "\n",
    "\n",
    "\n",
    "Logo:\n",
    "\n",
    "$$P(R|tweet)P(Relevante) > P(I|tweet)P(Irrelevante)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feita a an√°lise te√≥rica, vamos implantar o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1922,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula a frequ√™ncia absoluta da palavra no respectivo conjunto de dados\n",
    "def freq_absoluta(palavra,lista):\n",
    "    count=0\n",
    "    for i in range(0,len(lista)):\n",
    "        if palavra==lista[i]:\n",
    "            count+=1\n",
    "        else:\n",
    "            continue\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1923,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando a suaviza√ß√£o de laplace\n",
    "def laplace(frequencia_absoluta,palavras_pertecentes_a_classe):\n",
    "    return (frequencia_absoluta+1)/(len(palavras_pertecentes_a_classe)+len(elementos_nao_repetidos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1924,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_tweet_r(tweet):\n",
    "    '''\n",
    "    Calcula a probabilidade do tweet ser relevante\n",
    "    '''\n",
    "    prob_tweet=1 #Cont\n",
    "    quebra_tweet=tweet.split(',')\n",
    "    for palavra in quebra_tweet:\n",
    "        fa=freq_absoluta(palavra,list_r)\n",
    "        prob_palavra=laplace(fa,list_r)\n",
    "        prob_tweet*=prob_palavra\n",
    "           \n",
    "    return prob_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1925,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_tweet_i (tweet):\n",
    "    '''\n",
    "    Calcula a probabilidade do tweet ser irrelevante\n",
    "    '''\n",
    "    prob_tweet=1 #Cont\n",
    "    quebra_tweet=tweet.split(',')\n",
    "    for palavra in quebra_tweet:\n",
    "        fa=freq_absoluta(palavra,list_i)\n",
    "        prob_palavra=laplace(fa,list_i)\n",
    "        prob_tweet*=prob_palavra\n",
    "           \n",
    "    return prob_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1926,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando Nossa fun√ß√£o de retorno Naive_Bayes:\n",
    "def Naive_Bayes (tweet):\n",
    "    if(P_tweet_r(tweet)*P_r > P_tweet_i(tweet)*P_i):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Vendo a efic√°cia do modelo no conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1927,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando uma nova coluna para armazenar resultado da nossa fun√ß√£o Na√Øve_Bayes\n",
    "train['Classificador']=train.Clean.apply(Naive_Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1928,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>executivo da disney defendeu demiss√£o de gina ...</td>\n",
       "      <td>0</td>\n",
       "      <td>executivo,disney,defendeu,demiss√£o,gina,carano...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@daredvevil nao seriooo melhor dia üò≠ volta the...</td>\n",
       "      <td>1</td>\n",
       "      <td>daredvevil,nao,seriooo,melhor,dia,volta,precis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>preciso terminar mandalorian logo</td>\n",
       "      <td>1</td>\n",
       "      <td>preciso,terminar,logo,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toda vez que eu vejo o baby yoda usando a for√ß...</td>\n",
       "      <td>0</td>\n",
       "      <td>toda,vez,vejo,baby,yoda,usando,for√ßa,lembro,me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jon fraveau eu te amo obrigado por fazer the m...</td>\n",
       "      <td>1</td>\n",
       "      <td>jon,fraveau,amo,obrigado,fazer,big,fan,here,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevancia  \\\n",
       "0  executivo da disney defendeu demiss√£o de gina ...           0   \n",
       "1  @daredvevil nao seriooo melhor dia üò≠ volta the...           1   \n",
       "2                  preciso terminar mandalorian logo           1   \n",
       "3  toda vez que eu vejo o baby yoda usando a for√ß...           0   \n",
       "4  jon fraveau eu te amo obrigado por fazer the m...           1   \n",
       "\n",
       "                                               Clean  Classificador  \n",
       "0  executivo,disney,defendeu,demiss√£o,gina,carano...              0  \n",
       "1  daredvevil,nao,seriooo,melhor,dia,volta,precis...              1  \n",
       "2                             preciso,terminar,logo,              1  \n",
       "3  toda,vez,vejo,baby,yoda,usando,for√ßa,lembro,me...              0  \n",
       "4       jon,fraveau,amo,obrigado,fazer,big,fan,here,              1  "
      ]
     },
     "execution_count": 1928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1929,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acur√°cia do modelo foi de:  90.6 %\n"
     ]
    }
   ],
   "source": [
    "#Porcentagem de acerto de acerto no conjunto de Treino:\n",
    "\n",
    "x=train.loc[(train['Classificador']==1)&(train['Relevancia']==1),:].shape[0]\n",
    "y=train.loc[(train['Classificador']==0)&(train['Relevancia']==0),:].shape[0]\n",
    "print('A acur√°cia do modelo foi de: ',100*(x+y)/train.shape[0],'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1930,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificador</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.4</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>56.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificador     0     1\n",
       "Relevancia               \n",
       "0              34.4   9.4\n",
       "1               0.0  56.2"
      ]
     },
     "execution_count": 1930,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vendo a classifica√ß√£o efetiva \n",
    "pd.crosstab(train.Relevancia,train.Classificador,normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1931,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando no dataframe de teste\n",
    "test['Classificador']=test.Clean.apply(Naive_Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1932,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acur√°cia do modelo foi de:  55.111111111111114 %\n"
     ]
    }
   ],
   "source": [
    "x=test.loc[(test['Classificador']==1)&(test['Relevancia']==1),:].shape[0]\n",
    "y=test.loc[(test['Classificador']==0)&(test['Relevancia']==0),:].shape[0]\n",
    "print('A acur√°cia do modelo foi de: ',100*(x+y)/test.shape[0],'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1933,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificador</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.555556</td>\n",
       "      <td>42.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.222222</td>\n",
       "      <td>39.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificador          0          1\n",
       "Relevancia                         \n",
       "0              15.555556  42.666667\n",
       "1               2.222222  39.555556"
      ]
     },
     "execution_count": 1933,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vendo a classifica√ß√£o efetiva \n",
    "pd.crosstab(test.Relevancia,test.Classificador,normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1934,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem\t\tProbabilidade\n",
      "----------------------------------------\n",
      "Verdadeiros Positivos:\t\t0.481081\n",
      "Falsos Positivos:\t\t0.125000\n",
      "Verdadeiros Negativos:\t\t0.875000\n",
      "Falsos Negativos:\t\t0.518919\n"
     ]
    }
   ],
   "source": [
    "serie_0_test = test[test[\"Classificador\"] == 0]\n",
    "serie_1_test = test[test[\"Classificador\"] == 1]\n",
    "\n",
    "# Valores iniciais das quantidades de cada caso\n",
    "verdadeiros_positivos = 0\n",
    "falsos_positivos = 0\n",
    "verdadeiros_negativos = 0\n",
    "falsos_negativos = 0\n",
    "\n",
    "# Calcula a quantidade de tweets de cada um dos casos acima\n",
    "for i in range(len(test['Classificador'])):\n",
    "    if test['Classificador'][i] == 1 and test['Relevancia'][i] == 1:\n",
    "        verdadeiros_positivos += 1\n",
    "    elif test['Classificador'][i] == 0 and test['Relevancia'][i] == 1:\n",
    "        falsos_positivos += 1\n",
    "    elif test['Classificador'][i] == 0 and test['Relevancia'][i] == 0:\n",
    "        verdadeiros_negativos += 1\n",
    "    elif test['Classificador'][i] == 1 and test['Relevancia'][i] == 0:\n",
    "        falsos_negativos += 1\n",
    "\n",
    "# Retorna probabilidade para cada caso\n",
    "print(\"Contagem\\t\\tProbabilidade\")\n",
    "print(\"----------------------------------------\")\n",
    "print(\"%s:\\t\\t%f\" % ('Verdadeiros Positivos', verdadeiros_positivos/len(serie_1_test['Classificador'])))\n",
    "print(\"%s:\\t\\t%f\" % ('Falsos Positivos', falsos_positivos/len(serie_0_test['Classificador'])))\n",
    "print(\"%s:\\t\\t%f\" % ('Verdadeiros Negativos', verdadeiros_negativos/len(serie_0_test['Classificador'])))\n",
    "print(\"%s:\\t\\t%f\" % ('Falsos Negativos', falsos_negativos/len(serie_1_test['Classificador'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1935,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificador</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificador   0   1\n",
       "Relevancia           \n",
       "0              35  96\n",
       "1               5  89"
      ]
     },
     "execution_count": 1935,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test.Relevancia,test.Classificador,normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1936,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizaremos aqui o m√≥dulo sklearn que √© pr√≥prio para an√°lises de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1937,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Total</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>executivo da disney defendeu demiss√£o de gina ...</td>\n",
       "      <td>executivo,disney,defendeu,demiss√£o,gina,carano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@daredvevil nao seriooo melhor dia üò≠ volta the...</td>\n",
       "      <td>daredvevil,nao,seriooo,melhor,dia,volta,precis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>preciso terminar mandalorian logo</td>\n",
       "      <td>preciso,terminar,logo,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>toda vez que eu vejo o baby yoda usando a for√ß...</td>\n",
       "      <td>toda,vez,vejo,baby,yoda,usando,for√ßa,lembro,me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>jon fraveau eu te amo obrigado por fazer the m...</td>\n",
       "      <td>jon,fraveau,amo,obrigado,fazer,big,fan,here,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Relevancia                                              Total  \\\n",
       "0           0  executivo da disney defendeu demiss√£o de gina ...   \n",
       "1           1  @daredvevil nao seriooo melhor dia üò≠ volta the...   \n",
       "2           1                  preciso terminar mandalorian logo   \n",
       "3           0  toda vez que eu vejo o baby yoda usando a for√ß...   \n",
       "4           1  jon fraveau eu te amo obrigado por fazer the m...   \n",
       "\n",
       "                                               Clean  \n",
       "0  executivo,disney,defendeu,demiss√£o,gina,carano...  \n",
       "1  daredvevil,nao,seriooo,melhor,dia,volta,precis...  \n",
       "2                             preciso,terminar,logo,  \n",
       "3  toda,vez,vejo,baby,yoda,usando,for√ßa,lembro,me...  \n",
       "4       jon,fraveau,amo,obrigado,fazer,big,fan,here,  "
      ]
     },
     "execution_count": 1937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Juntando os tweets em um unico DF\n",
    "test = pd.read_excel(filename, sheet_name = 'Teste').drop('Relevancia',axis=1)\n",
    "test['Relevancia']=test['New']\n",
    "test['Total']=test['Teste']\n",
    "test=test.drop(['New','Teste'],axis=1)\n",
    "\n",
    "train = pd.read_excel(filename, sheet_name = 'Treinamento')\n",
    "train['Total']=train['Treinamento']\n",
    "train=train.drop('Treinamento',axis=1)\n",
    "\n",
    "#Concatenando as tabelas\n",
    "data_set=pd.concat([train,test])\n",
    "\n",
    "#Limpando os tweets\n",
    "data_set['Clean']=data_set['Total'].apply(aplica)\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1894,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clean</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dps,insistirem,mt,come√ßando,espero,q,realmente...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>lula,presidente,podcasts,2,horas,acabando,bras...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>fonte,serotonina,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>tebaldopaladino,acabamos,maratona,star,wars,tbm,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>peepdark,dark,vou,come√ßar,terminar,sw,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>hmm,q,hj,vaza,foto,skins,passe,dias,antes,temp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>adeus,vou,ver,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>final,to,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>_nay_viana,gambito,rainha,bom,legal,tbm,nerdic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>ta,bom,ta,bom,escuta,imagina,par√≥dia,porno,chama,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Clean  Classificador\n",
       "10   dps,insistirem,mt,come√ßando,espero,q,realmente...              1\n",
       "107  lula,presidente,podcasts,2,horas,acabando,bras...              1\n",
       "170                                  fonte,serotonina,              1\n",
       "224   tebaldopaladino,acabamos,maratona,star,wars,tbm,              1\n",
       "156             peepdark,dark,vou,come√ßar,terminar,sw,              1\n",
       "..                                                 ...            ...\n",
       "199  hmm,q,hj,vaza,foto,skins,passe,dias,antes,temp...              1\n",
       "492                                     adeus,vou,ver,              1\n",
       "39                                           final,to,              1\n",
       "318  _nay_viana,gambito,rainha,bom,legal,tbm,nerdic...              1\n",
       "284  ta,bom,ta,bom,escuta,imagina,par√≥dia,porno,chama,              0\n",
       "\n",
       "[290 rows x 2 columns]"
      ]
     },
     "execution_count": 1894,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Seperando aleatoriamente\n",
    "#Considerando que temos 725 tweets, e fora solicitado 200-300, precisaremos de 200/500, ou seja, cerca de 290 tweets\n",
    "#Para o split. Essa porcentagem √© de 0.40, que colocaremos no par√¢metros abaixo\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Quebrando nossos atributos e r√≥tulos aleatoriamente pelo m√©todo abaixo:\n",
    "#OBS: Como n√£o utilizamos o par√¢metro random_state=number, estamos garantindo que a cada loop sobre o split\n",
    "#ser√° aleatoriamente e diferentemente organizado\n",
    "for i in range(0,10):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(data_set[['Clean']],data_set.Relevancia,\n",
    "                                               test_size=0.40)\n",
    "    \n",
    "    \n",
    "    def laplace(frequencia_absoluta,palavras_pertecentes_a_classe):\n",
    "        return (frequencia_absoluta+1)/(len(palavras_pertecentes_a_classe)+len(elementos_nao_repetidos))\n",
    "    \n",
    "   \n",
    "    X_test['Classificador']=X_test.Clean.apply(Naive_Bayes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicio_r (palavra):\n",
    "    \n",
    "    nova=sn.Search(palavra).synonyms()   #Buscando sin√¥nimos\n",
    "    P_nova=0\n",
    "    \n",
    "    if nova != 404:\n",
    "        \n",
    "        for i in range(len(nova)):\n",
    "        \n",
    "            if (i != len(nova)-1):\n",
    "                if (nova[i] in palavras_r) and (nova[i] not in lista_r):\n",
    "                    P_nova=rel_relevantes[nova[i]]\n",
    "                    return P_nova\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            else:\n",
    "                return 1\n",
    "    else:\n",
    "        return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicio_i (palavra):\n",
    "    \n",
    "    nova=sn.Search(palavra).synonyms()   #Buscando sin√¥nimos\n",
    "    P_nova=0\n",
    "    \n",
    "    if nova != 404:\n",
    "    \n",
    "        for i in range(len(nova)):\n",
    "            \n",
    "            if (i != len(nova)-1):\n",
    "            \n",
    "                if (nova[i] in palavras_r) and (nova[i] not in lista_i):\n",
    "                    P_nova=rel_relevantes[nova[i]]\n",
    "                    return P_nova\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            else:\n",
    "                return 1\n",
    "    else:\n",
    "        return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
