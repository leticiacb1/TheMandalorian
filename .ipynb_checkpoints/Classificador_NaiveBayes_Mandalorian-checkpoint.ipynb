{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Let√≠cia Co√™lho Barbosa\n",
    "\n",
    "Nome: Matheus Silva Melo de Oliveira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextualiza√ß√£o\n",
    "\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas Utilizadas\n",
    "\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install emoji\n",
    "#!pip install pysinonimos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import re \n",
    "import emoji\n",
    "import pysinonimos.sinonimos as sn\n",
    "import nltk\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmando diret√≥rio de trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\mathe_vz6v46f\\OneDrive\\Documentos\\Arquivos INSPER 2¬∞ SEMESTRE\\C-Dados\\TheMandalorian\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Banco de Dados\n",
    "\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'mandalorian.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>executivo da disney defendeu demiss√£o de gina ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@daredvevil nao seriooo melhor dia üò≠ volta the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>preciso terminar mandalorian logo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toda vez que eu vejo o baby yoda usando a for√ß...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jon fraveau eu te amo obrigado por fazer the m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevancia\n",
       "0  executivo da disney defendeu demiss√£o de gina ...           0\n",
       "1  @daredvevil nao seriooo melhor dia üò≠ volta the...           1\n",
       "2                  preciso terminar mandalorian logo           1\n",
       "3  toda vez que eu vejo o baby yoda usando a for√ß...           0\n",
       "4  jon fraveau eu te amo obrigado por fazer the m...           1"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the mandalorian √© uma s√©rie com dinheiro e tec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agora comecei mandalorian confiando novamente ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@fepazo1 @gabriel_ns1999 @joelmsimmons @jurand...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu assisti 3 minutos de mandalorian e emocionei</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @anakinwar: j√° ta                          ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevancia\n",
       "0  the mandalorian √© uma s√©rie com dinheiro e tec...           1\n",
       "1  agora comecei mandalorian confiando novamente ...           1\n",
       "2  @fepazo1 @gabriel_ns1999 @joelmsimmons @jurand...           1\n",
       "3    eu assisti 3 minutos de mandalorian e emocionei           1\n",
       "4  rt @anakinwar: j√° ta                          ...           0"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador autom√°tico de sentimento\n",
    "\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Definindo Fun√ß√µes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mathe_vz6v46f\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Limpando os tweets retirando pontos desnecessarios\n",
    "def limpeza(tweet):\n",
    "    punctuation = '[!-.:?;\\n|]'                # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern,'', tweet)\n",
    "    return text_subbed\n",
    "\n",
    "#Limpando os tweets retirando emojis\n",
    "def retira_emoji(content: str):\n",
    "        modified = re.sub(emoji.get_emoji_regexp(), r\"\", content)\n",
    "        modified = re.sub(':[^>]+:', '', modified)\n",
    "        modified = re.sub('<[^>]+>', '', modified)\n",
    "        return modified.strip() \n",
    "\n",
    "#Armazenando listas com preposi√ß√µes na l√≠ngua portuguesa\n",
    "nltk.download('stopwords')\n",
    "prep = nltk.corpus.stopwords.words('portuguese')\n",
    "prep.append('')\n",
    "\n",
    "# Define fun√ß√£o que aplica remo√ß√£o de preposi√ß√µes\n",
    "def limpa_preposicao(lista):\n",
    "    sem_prep=[]     \n",
    "    for palavra in lista: \n",
    "        if palavra in prep: \n",
    "            continue\n",
    "        else:\n",
    "            sem_prep.append(palavra)\n",
    "            \n",
    "    return sem_prep\n",
    "    \n",
    "# Transformando tweets em lower case:\n",
    "def lower(tweet):\n",
    "    return tweet.lower()\n",
    "\n",
    "#retira escritas comuns em tweets, mas irrelevantes para an√°lise de dados\n",
    "def tweet_to_frase(lista):\n",
    "    for i,word in enumerate(lista):\n",
    "        if 'rt' in word or 'https' in word or '@' in word:\n",
    "            lista[i]=lista[i].replace(word,'null')\n",
    "    new_list=[x for x in lista if x!='null']\n",
    "    return new_list\n",
    "\n",
    "def transcreve_emoji(lista):\n",
    "    emojis=re.findall(emoji.get_emoji_regexp(),lista)                   #Tornando os emojis em strings descritivas\n",
    "    for i,emoji1 in enumerate(emojis):                              #Alguns emojis n√£o possuem transcri√ß√£o para portugu√™s\n",
    "            if emoji1 in UNICODE_EMOJI['pt']:\n",
    "                emojis[i]=UNICODE_EMOJI['pt'][emoji1].replace(':',',')\n",
    "            else:\n",
    "                emojis[i]=UNICODE_EMOJI['en'][emoji1].replace(':',',')\n",
    "    return emojis\n",
    "\n",
    "#Transformando lista em string\n",
    "def list_to_string(lista):\n",
    "    return ','.join(lista)\n",
    "\n",
    "#Transformando string em lista\n",
    "def string_to_list(string):\n",
    "    return string.split()\n",
    "\n",
    "   \n",
    "# Concatenando tweets palavras+emojis limpos:\n",
    "def aplica(tweet):\n",
    "    \n",
    "    #captando emojis\n",
    "    emoji_transcrito=list_to_string(transcreve_emoji(tweet))\n",
    "    \n",
    "    #aplicando todas as fun√ß√µes definidas\n",
    "    frase_separada=list_to_string(tweet_to_frase(limpa_preposicao(string_to_list(limpeza(lower(retira_emoji(tweet)))))))\n",
    "    \n",
    "    #retornando uma string limpa e com emojis transcritos\n",
    "    return frase_separada+','+emoji_transcrito\n",
    "\n",
    "def frases_to_words (Serie_frases):\n",
    "    \n",
    "    texto=''\n",
    "    \n",
    "    for palavra in Serie_frases:\n",
    "        texto+=str(palavra)                        #Criando uma string gigante com todas as palavras das frases\n",
    "    \n",
    "    lista_palavras=texto.split(',')                #Criando lista das palavras contidas na vari√°vel texto\n",
    "    return pd.Series(lista_palavras)               #Retornando uma s√©rie de palavras contida nas frases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando palavras em vari√°veis categ√≥ricas:\n",
    "train['Treinamento'] = train['Treinamento'].astype('category')\n",
    "test['Teste'] = test['Teste'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando fun√ß√µes de limpeza:\n",
    "train['Clean']=train['Treinamento'].apply(aplica)\n",
    "\n",
    "test['Clean']=test['Teste'].apply(aplica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando dados de treino por relev√¢ncia:\n",
    "\n",
    "train_relevantes=train[train['Relevancia']==1]\n",
    "train_irrelevantes=train[train['Relevancia']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Serie de palavras relevantes e irrelevantes no conjunto treino:\n",
    "\n",
    "palavras_r= frases_to_words(train_relevantes['Clean'])\n",
    "palavras_i= frases_to_words(train_irrelevantes['Clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 nao\n",
       "1                             seriooo\n",
       "2                              melhor\n",
       "3                                 dia\n",
       "4                               volta\n",
       "                    ...              \n",
       "3122                              the\n",
       "3123                      mandalorian\n",
       "3124                                 \n",
       "3125    m√£os_juntas_pele_morena_clara\n",
       "3126                                 \n",
       "Length: 3127, dtype: object"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conferindo resultado:\n",
    "\n",
    "palavras_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando texto com palavras relevantes:\n",
    "\n",
    "texto_r=''\n",
    "\n",
    "for palavra in train_relevantes['Clean']:\n",
    "    texto_r+=str(palavra)\n",
    "#print(texto_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando texto com palavras irrelevantes:\n",
    "texto_i=''\n",
    "\n",
    "for palavra in train_irrelevantes['Clean']:\n",
    "    texto_i+=str(palavra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequ√™ncia relativa das palavras:\n",
    "\n",
    "rel_relevantes=palavras_r.value_counts(normalize=True)\n",
    "rel_irrelevantes=palavras_i.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conferindo resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para usar em laplace:\n",
    "list_i=rel_irrelevantes.index.tolist()\n",
    "list_r=rel_relevantes.index.tolist()\n",
    "elementos_nao_repetidos=set(list_i+list_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           executivo\n",
       "1                              disney\n",
       "2                            defendeu\n",
       "3                            demiss√£o\n",
       "4                                gina\n",
       "                    ...              \n",
       "5598                              the\n",
       "5599                      mandalorian\n",
       "5600                                 \n",
       "5601    m√£os_juntas_pele_morena_clara\n",
       "5602                                 \n",
       "Length: 5603, dtype: object"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#S√©rie representante do conjunto universo de todas as palavras:\n",
    "palavras_i=palavras_i.tolist()\n",
    "palavras_r=palavras_r.tolist()\n",
    "#total=palavras_i+palavras_r\n",
    "total=pd.Series(palavras_i+palavras_r)             \n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequ√™ncia das palvras no total:\n",
    "rel_total=total.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mandalorian    0.080493\n",
       "               0.046225\n",
       "the            0.041406\n",
       "pra            0.010530\n",
       "wars           0.008924\n",
       "                 ...   \n",
       "diversidade    0.000178\n",
       "decidi         0.000178\n",
       "pel√∫cia        0.000178\n",
       "batalha        0.000178\n",
       "perdido        0.000178\n",
       "Length: 2002, dtype: float64"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conferindo resultado\n",
    "rel_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando as Probabilidades "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P_{relevante}= \\frac{Palavras_{relevantes}}{Total_{palavras}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P_{irrelevante}= \\frac{Palavras_{irrelevantes}}{Total_{palavras}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onde, sabemos que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P_{relevante}+ P_{irrelevante}=1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilidade tweet ser relevante ou irrelevante:\n",
    "P_r=len(palavras_r)/len(total)\n",
    "P_i=len(palavras_i)/len(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingenuidade do classificador Navie Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(R|tweet)= \\frac{P(tweet \\cap R)}{P(tweet)} $$\n",
    "$$ P(tweet|R)= \\frac{P(tweet \\cap R)}{P(R)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(tweet \\cap R) = P(R|tweet) P(tweet) $$\n",
    "$$ P(tweet \\cap R) = P(tweet|R) P(R) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sendo a Probabiliadde de Navie Bayes:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(R|tweet)= \\frac{P(tweet|R) P(R)}{P(tweet)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A probabilidade $P(tweet|R)$, pode ser calculada considerando a independ√™ncia entre as palavras, ou seja, a probabilidade de certa palavra aparecer n√£o interfere na probabilidade de outras:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(tweet|R) = P(palavra1|R)P(palavra2|R)...P(palavraN|R)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos portayndo como porbabilidade de um tweet ser relevante:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(R|tweet) = \\frac{P(palavra1|R)P(palavra2|R)...P(palavraN|R) P(R)}{P(tweet)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogamento, para $P(I|tweet)$, teriamos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(I|tweet)=\\frac{P(palavra1|I)P(palavra2|I)...P(palavraN|I) P(I)}{P(tweet)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, a fun√ß√£o Navie Bayes classificaria como relevante caso:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(R|tweet)>P(I|tweet)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_r=['mandalorian','de','the','√©','que','a','e','o','eu','da','mas','com']\n",
    "lista_i=['mandalorian','de',' ','the','e','o','a','que','do','√©','eu','da','em','no','um','pra','com']\n",
    "lista_r_new=[x for x in lista_r if x not in prep]\n",
    "lista_i_new=[x for x in lista_i if x not in prep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def teste(palavra,r):\n",
    "    count=0\n",
    "    for i in range(0,len(r)):\n",
    "        if palavra==r[i]:\n",
    "            count+=1\n",
    "        else:\n",
    "            continue\n",
    "    return count+1\n",
    "teste('augusto',['ele'])            \n",
    "    \n",
    "list_i=rel_irrelevantes.index.tolist()\n",
    "list_r=rel_relevantes.index.tolist()\n",
    "elementos_nao_repetidos=set(list_i+list_r)\n",
    "teste('augusto',['ele']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_tweet_r (tweet):\n",
    "    \n",
    "    c=1\n",
    "    r=tweet.split(',')\n",
    "    #r=[x for x in r if x!='mandalorian']\n",
    "    for palavra in r:\n",
    "        \n",
    "        x=teste(palavra,list_r)\n",
    "        k=x/(len(list_r)+len(elementos_nao_repetidos))\n",
    "        c*=k\n",
    "#         if(palavra in palavras_r) and (palavra not in lista_r_new) :\n",
    "            \n",
    "#             c*=rel_relevantes[palavra]\n",
    "#         elif palavra in rel_total:\n",
    "#             c*=rel_total[palavra]\n",
    "#             #c*=dicio_r(palavra)\n",
    "#         else:\n",
    "#             continue\n",
    "           \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_tweet_i (tweet):\n",
    "    \n",
    "    \n",
    "    c=1\n",
    "    \n",
    "    r=tweet.split(',')\n",
    "    #r=[x for x in r if x!='mandalorian']\n",
    "    for palavra in r:\n",
    "        \n",
    "        x=teste(palavra,list_i)\n",
    "        k=x/(len(list_i)+len(elementos_nao_repetidos))\n",
    "        c*=k\n",
    "    \n",
    "#     for palavra in tweet.split(','):\n",
    "#         if(palavra in palavras_i) and (palavra not in lista_i_new):\n",
    "#             c*=rel_irrelevantes[palavra]\n",
    "        \n",
    "#         elif palavra in rel_total: \n",
    "#             c*=rel_total[palavra]\n",
    "#             #c*=dicio_i(palavra)\n",
    "#         else:\n",
    "#             continue\n",
    "        \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando Nossa fu√ß√£o Naive_Bayes:\n",
    "\n",
    "def Naive_Bayes (tweet):\n",
    "    if(P_tweet_r(tweet)*P_r > P_tweet_i(tweet)*P_i):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.010494842759616e-67"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " P_tweet_r('dps,de,insistirem,mt,estou,come√ßando,mandalorian,espero,q,realmente,seja,o,caso,de,salva√ß√£o,do,star,wars,alegria,Michel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7828817168946249e-68"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_tweet_i('dps,de,insistirem,mt,estou,come√ßando,mandalorian,espero,q,realmente,seja,o,caso,de,salva√ß√£o,do,star,wars,alegria, Michel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando uma nova coluna para armazenar resultado da nossa fun√ß√£o Navie_Bayes\n",
    "\n",
    "train['Classificador']=train.Clean.apply(Naive_Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>executivo da disney defendeu demiss√£o de gina ...</td>\n",
       "      <td>0</td>\n",
       "      <td>executivo,disney,defendeu,demiss√£o,gina,carano...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@daredvevil nao seriooo melhor dia üò≠ volta the...</td>\n",
       "      <td>1</td>\n",
       "      <td>nao,seriooo,melhor,dia,volta,the,mandalorian,p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>preciso terminar mandalorian logo</td>\n",
       "      <td>1</td>\n",
       "      <td>preciso,terminar,mandalorian,logo,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toda vez que eu vejo o baby yoda usando a for√ß...</td>\n",
       "      <td>0</td>\n",
       "      <td>toda,vez,vejo,baby,yoda,usando,for√ßa,the,manda...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jon fraveau eu te amo obrigado por fazer the m...</td>\n",
       "      <td>1</td>\n",
       "      <td>jon,fraveau,amo,obrigado,fazer,the,mandalorian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>√∫ltimo ep de mandalorian, n√£o estou preparada</td>\n",
       "      <td>1</td>\n",
       "      <td>√∫ltimo,ep,mandalorian,preparada,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>minha prioridade agora √© terminar the mandalorian</td>\n",
       "      <td>1</td>\n",
       "      <td>prioridade,agora,terminar,the,mandalorian,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>agora vou come√ßar a ver the mandalorian üôèüèº</td>\n",
       "      <td>1</td>\n",
       "      <td>agora,vou,come√ßar,ver,the,mandalorian,,m√£os_ju...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>@jurandirfilho tem nem compara√ß√£o n√© man, mand...</td>\n",
       "      <td>0</td>\n",
       "      <td>compara√ß√£o,n√©,man,mandalorian,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>mandalorian por favor retire seu capacete, que...</td>\n",
       "      <td>0</td>\n",
       "      <td>mandalorian,favor,retire,capacete,quero,ver,pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Relevancia  \\\n",
       "0    executivo da disney defendeu demiss√£o de gina ...           0   \n",
       "1    @daredvevil nao seriooo melhor dia üò≠ volta the...           1   \n",
       "2                    preciso terminar mandalorian logo           1   \n",
       "3    toda vez que eu vejo o baby yoda usando a for√ß...           0   \n",
       "4    jon fraveau eu te amo obrigado por fazer the m...           1   \n",
       "..                                                 ...         ...   \n",
       "495      √∫ltimo ep de mandalorian, n√£o estou preparada           1   \n",
       "496  minha prioridade agora √© terminar the mandalorian           1   \n",
       "497         agora vou come√ßar a ver the mandalorian üôèüèº           1   \n",
       "498  @jurandirfilho tem nem compara√ß√£o n√© man, mand...           0   \n",
       "499  mandalorian por favor retire seu capacete, que...           0   \n",
       "\n",
       "                                                 Clean  Classificador  \n",
       "0    executivo,disney,defendeu,demiss√£o,gina,carano...              0  \n",
       "1    nao,seriooo,melhor,dia,volta,the,mandalorian,p...              1  \n",
       "2                   preciso,terminar,mandalorian,logo,              1  \n",
       "3    toda,vez,vejo,baby,yoda,usando,for√ßa,the,manda...              0  \n",
       "4    jon,fraveau,amo,obrigado,fazer,the,mandalorian...              1  \n",
       "..                                                 ...            ...  \n",
       "495                   √∫ltimo,ep,mandalorian,preparada,              1  \n",
       "496         prioridade,agora,terminar,the,mandalorian,              1  \n",
       "497  agora,vou,come√ßar,ver,the,mandalorian,,m√£os_ju...              1  \n",
       "498                     compara√ß√£o,n√©,man,mandalorian,              0  \n",
       "499  mandalorian,favor,retire,capacete,quero,ver,pe...              0  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Porgentagem de acerto no conjunto de Treino:\n",
    "\n",
    "x=train.loc[(train['Classificador']==1)&(train['Relevancia']==1),:].shape[0]\n",
    "y=train.loc[(train['Classificador']==0)&(train['Relevancia']==0),:].shape[0]\n",
    "(x+y)/train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Classificador']=test.Clean.apply(Naive_Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5244444444444445"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=test.loc[(test['Classificador']==1)&(test['Relevancia']==1),:].shape[0]\n",
    "y=test.loc[(test['Classificador']==0)&(test['Relevancia']==0),:].shape[0]\n",
    "(x+y)/test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificador</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.168889</td>\n",
       "      <td>0.377778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097778</td>\n",
       "      <td>0.355556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificador         0         1\n",
       "Relevancia                       \n",
       "0              0.168889  0.377778\n",
       "1              0.097778  0.355556"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fp=test.loc[(test['Classificador']==0)&(test['Relevancia']==1),:].shape[0]\n",
    "# tp=test.loc[(test['Classificador']==1)&(test['Relevancia']==1),:].shape[0]\n",
    "# fn=test.loc[(test['Classificador']==1)&(test['Relevancia']==0),:].shape[0]\n",
    "# tn=test.loc[(test['Classificador']==0)&(test['Relevancia']==0),:].shape[0]\n",
    "\n",
    "# test['Classificador']=\n",
    "pd.crosstab(test.Relevancia,test.Classificador,normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicio_r (palavra):\n",
    "    \n",
    "    nova=sn.Search(palavra).synonyms()   #Buscando sin√¥nimos\n",
    "    P_nova=0\n",
    "    \n",
    "    if nova != 404:\n",
    "        \n",
    "        for i in range(len(nova)):\n",
    "        \n",
    "            if (i != len(nova)-1):\n",
    "                if (nova[i] in palavras_r) and (nova[i] not in lista_r):\n",
    "                    P_nova=rel_relevantes[nova[i]]\n",
    "                    return P_nova\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            else:\n",
    "                return 1\n",
    "    else:\n",
    "        return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicio_i (palavra):\n",
    "    \n",
    "    nova=sn.Search(palavra).synonyms()   #Buscando sin√¥nimos\n",
    "    P_nova=0\n",
    "    \n",
    "    if nova != 404:\n",
    "    \n",
    "        for i in range(len(nova)):\n",
    "            \n",
    "            if (i != len(nova)-1):\n",
    "            \n",
    "                if (nova[i] in palavras_r) and (nova[i] not in lista_i):\n",
    "                    P_nova=rel_relevantes[nova[i]]\n",
    "                    return P_nova\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            else:\n",
    "                return 1\n",
    "    else:\n",
    "        return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
